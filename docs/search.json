{
  "articles": [
    {
      "path": "index.html",
      "title": "NMFS OpenSci JupyterHub",
      "description": "Testing JupyterHubs for Python and R development environments.\n",
      "author": [],
      "contents": "\n\nContents\nSetting up Git to remember you\nWhat is a JupyterHub\n\nI have set us up a JupyterHub/RStudio cloud-computing hub on Azure. It’s on Kubernetes and will spin up VMs as needed. The VMs are not huge: 2CPU & 8 Gig RAM.\nhttps://jhub.opensci.live/hub/login\nLogin via GitHub. Only members of the JHub GitHub team can log on. This is a testing environment. Contact Eli if you want to test it out.\nInstructions: It should be pretty self-explanatory.\nChose Python or R\nIt is based on the Openscapes docker images and is fairly full-featured but during testing let me know any libraries you need loaded.\nDoes your work persist? Yes. It should be like your computer.\nIs there a limit to storage? Yes. I don’t know what it is. Go ahead an use it so I can get a sense of storage needs.\nHow do I link to my GitHub repositories? Follow these instructions https://snowex-2022.hackweek.io/preliminary/git.html\nPost any comments in the discussion so we all can follow them.\nSetting up Git to remember you\nBasically\nOpen up a terminal\ngit config --global user.name \"Your Name\"\ngit config --global user.email \"yourname@your.com\"\ngit config --global credential.helper store\nMake a PAT on GitHub\nHead back to the JupyterHub and do a push. It’ll ask for your username and password. After that it will remember.\nWhat is a JupyterHub\nRead about why cloud compute environments are great. This one is the same as the SnowEx Hackweek one except that it also has RStudio server: https://snowex-2022.hackweek.io/preliminary/jupyterhub.html\n\n\n\n",
      "last_modified": "2023-06-16T17:40:34-07:00"
    },
    {
      "path": "JHub-User-Guide.html",
      "title": "User Instructions",
      "description": "How to use the hub\n",
      "author": [],
      "contents": "\n\nContents\nLogin\nSpin up your server\nChoose your platform\nLet’s choose RStudio\nClone a repo\nTell Git who you are\n\nLet’s choose JupyterLab\nTell Git who you are\nClone a Git repo\n\nStop your server\n\nLogin\nhttps://jhub.opensci.live/hub/login\nYou will see this. Choose Python for Python only; choose R for Python and R.\n\nSpin up your server\nYou will see this as your server spins up\n\nChoose your platform\nYou can code in RStudio, JupyterLab or Terminal.\n\nLet’s choose RStudio\n\nClone a repo\nChoose ‘new project’ (top right) and Version Control.\n\nTell Git who you are\nTell Git who you are and save your authentication info. You only do this once (or until your PAT expires). Run this code from the R console (not terminal).\nusethis::use_git_config(user.name = \"YourName\", user.email = \"your@email.com\")\nNow create a personal access token for authentication. SAVE the token because you will need it in the next step.\nusethis::create_github_token() \nNow run this and paste in the token.\ngitcreds::gitcreds_set()\nRestart R. You can chose your project from the dropdown on the top right to do this.\nNow commit a change and push.\nNote, you can also run the commands below from a terminal window.\ngit config --global user.name \"YourName\"\ngit config --global user.email \"your@email.com\"\ngit config --global credential.helper store\nLet’s choose JupyterLab\nAny of the browser tabs with the Jupyter icon are JupyterLab.\nBe careful because you can be in RStudio with one GitHub repository and you could open the same repo in JupyterLab and easily create merge conflicts. Just be aware that they are in separate file systems so changes on RStudio will not be reflected in JupyterLab. It is not like you are on one computer.\nTell Git who you are\nBut I just did that with RStudio! I know but the JLab instance is in a different environment and doesn’t know what you did in the RStudio environment.\nOpen a terminal. You do this from the Launcher window. You can always open a new launcher window by clicking the little + tab\n\nNow click Terminal and run this code\ngit config --global user.name \"YourName\"\ngit config --global user.email \"your@email.com\"\ngit config --global credential.helper store\nCreate a PAT or use the one you created for RStudio\nMake a commit and push with the PAT as the password. Now you are set (until your PAT expires).\nClone a Git repo\nClick the Git icon on the left and you can clone a repo.\n\nStop your server\nIt will stop on it’s own after awhile, but if it hangs, you can stop it and restart it. With File > Hub Control Panel\n\n\n\n",
      "last_modified": "2023-06-16T17:40:35-07:00"
    },
    {
      "path": "Set-up-daskhub.html",
      "title": "DaskHub Set-up",
      "description": "Setting up a multi-user JupyterHub with Dask enabled\n",
      "author": [],
      "contents": "\n\nContents\nCreate your Kubernetes cluster\nInstall DaskHub on your cluster\nConnect to your cluster\nCreate dconfig.yaml\nInstall daskhub via helm chart\nSet-up your external IP address\n\nStep 2 Set up https\nCreate a domain name\nCreate a DNS entry\nTest if the url is working\nSet-up https on your JupyterHub\nUpdate the JupyterHub installation\nTest if https is working\n\nStep 3 Set up GitHub authentication\nCreate a new Oauth Application on GitHub\nCreate a team in your GitHub org\nEdit the dconfig.yaml file\nUpdate the hub\nTest\n\nSet up the container image\nUpdate the hub\n\nChanging the VM size\nCreate a separate disk for user data\nCreate disk\nPVC\nPV\nTell the hub about the disk\n\nTroubleshooting\nRefs I used\nOverall\nStorage\n\nSetting up a shared data disk\nS3 access\n\nThis is my notes for setting this up on Azure. Attempting to replicate the Openscapes 2i2c JupyterHub: https://github.com/2i2c-org/infrastructure/tree/master/config/clusters/openscapes\nThat hub is on AWS and is designed for large workshops (100+) however the NMFS OpenSci JHub is quite similar. Main difference at the moment is that I don’t have a shared drive set-up and the user persistent volume (storage) is on the same VM as the user node for their Jupyter Notebook. This means that I cannot have multiple VM sizes. Need to fix so that user can pick a larger VM for a task if needed.\nCreate your Kubernetes cluster\nLog into https:\\\\portal.azure.com\nGet to the dashboard that looks similar to this.\n\nClick on the Kubernetes Services button and you should see something like this\n\nClick Create Kubernetes Cluster\nAt this point, you will get to the set-up with lots of tabs.\nYou need to select the resource group if you are in a subscription for an organization. Don’t know what resource group to use, ask the admins.\nYou need to give your Kubernetes cluster a name. For example, jhub or daskhub or whatever.\nYou need to chose the AWS region. If you are using AWS S3 file access (big data in the cloud), then you need to be on the same region as the files you are accessing. Do you have no idea? Then you are probably not using AWS S3 file access. In that case, just go with the default or something close to you.\nNext you chose the “Node size”. This is the size of the base virtural machine (VM). It is going to spin up as many as it needs. The default is Standard DS2 v2 which as 2 CPU, 7 Gig RAM and 1T memory. This is fine for set-up. You can add more (bigger VMs later). Accept autoscaling since this is a multi-user hub.\nThe first tab is all you need for now. Later you may want to allow the user, to choose a different base VM. You can do that by adding node-pools. That’ll be covered after the initial set-up. For now, just get your basic hub working. You can add more VM sizes later.\nClick “Review and Create”\nWait for validation tests to pass.\nClick “Create”.\nOnce it is done deploying, you will see this.\n\nInstall DaskHub on your cluster\nThese next steps are done in the shell after connecting to your cluster. First you need to get to the shell.\nConnect to your cluster\nOnce you have created your Kubernetes cluster, you want to go to its dashboard (by clicking on the name you gave it). You’ll see something like this (I named mine daskhub).\n\nClick on the Connect icon in the nav bar at top.\nYou then see this\n\nClick on the link that says “Open Cloud Shell”.\n\nYou will get to a terminal. Paste in the two commands in the previous image (the commands that show up for you that is).\nCreate dconfig.yaml\nThis will be the configuration file for your Dask-enabled JupyterHub. For now, it can be just comments. Note the name is unimportant but should end in .yaml. I am using dconfig.yaml instead of config.yaml since I already have a config.yaml file for something else–and I have not figured out how to install different hubs in different directories or even different clusters in different directories (I have much to learn…).\nnano dconfig.yaml\nThis will open the nano editor. Edit your file. You can do # just blank for now. Then Cntl-O to save and Cntl-X to exit.\nInstall daskhub via helm chart\nInstructions: https://artifacthub.io/packages/helm/dask/daskhub .\nCheck that helm is installed\nhelm version\nTell helm about the dask helm repository\nhelm repo add dask https://helm.dask.org\nhelm repo update\nNow install\nhelm upgrade --wait --install --render-subchart-notes \\\n    dhub dask/daskhub \\\n    --namespace=dhub --create-namespace \\\n    --values=dconfig.yaml\nYou will see this on successful installation (it’s long. much has been cut). \nSet-up your external IP address\nkubectl config set-context $(kubectl config current-context) --namespace dhub\nkubectl --namespace=dhub get service proxy-public\nThese commands will show the the IP address. Save the public IP address. You will need it in step 2. Look for the IP address under EXTERNAL-IP.\nStep 2 Set up https\nYou can log out of your cluster. The next steps are done elsewhere.\nCreate a domain name\nYou will need a domain name for https which you want for security (and JHub won’t stop complaining if you don’t). Find a domain name provider and set one up. It is not expensive. I used GoDaddy.\nCreate a DNS entry\nLet’s pretend you set up bluemountain123.live as the domain. Go to the DNS settings for your domain. Add a type A record. This will do 2 things. First this will create the subdomain that you will use to access your JupyterHub. So let’s say you create, dhub as the type A DNS entry. Then dhub.bluemountain123.live will be the url. You can have as many subdomains as you need.\n\nTest if the url is working\nhttp:\\\\dhub.bluemountain123.live would be the url using the example domain above. Test that it is working (shows a JupyterHub login) before moving on. This is what you should see:\n\nSet-up https on your JupyterHub\nLog back into your Kubernetes cluster: go to portal.azure.com, click on your Kubernetes cluster name, and then click on “Connect”. Then click on “Open Cloud Shell”. Read documentation about https\nOnce you are on the shell, type\nnano dconfig.yaml\nto edit the config file. Paste this in and save. Note the additional jupyterhub: in the yaml file. This is not in a plain JupyterHub with Kubernetes config file (i.e. in a non-daskhub, the jupyterhub: bit is not there and everything is moved to left by 2 spaces).\njupyterhub:\n  proxy:\n    https:\n      enabled: true\n      hosts:\n        - dhub.bluemountain123.live\n      letsencrypt:\n        contactEmail: your@email.com\nUpdate the JupyterHub installation\nAnytime you change dconfig.yaml you need to run this code.\nhelm upgrade --cleanup-on-fail --render-subchart-notes dhub dask/daskhub --namespace dhub --version=2023.1.0 --values dconfig.yaml\nTest if https is working\nTry https:\\\\dhub.bluemountain123.live and you should see the JupyterHub login without that http warning.\nStep 3 Set up GitHub authentication\nOptional, if you want to manage who can login via GitHub Team. I am going to show an example where I use a team on a GitHub organization to manage authentication. There are many other ways to manage users. Google to find that.\nCreate a new Oauth Application on GitHub\nThis is going to be associated with your (personal) GitHub account, but you can use a team on a GitHub org that you are owner of.\nLog into GitHub and go to GitHub > Settings > Developer Settings > New Oauth Application\nLook carefully at how I filled in the boxes.\n\nNext you will see something like this\n\nYou need to copy the ID and then click the create secrets button and save the secret. Save those for later.\nCreate a team in your GitHub org\nYou will be added by default and add anyone else who needs access to the hub. Let’s say your org is MyOrg and the team is called DaskHub. So then the allowed organization is MyOrg:DaskHub. You can leave off :DaskHub if you want to allow all members of the organization to log in.\nEdit the dconfig.yaml file\nnano dconfig.yaml\nAdd to your config file so it is now this. Replace the id, secret and url with your values. We need to set the KubeSpawner working directory because the Openscapes Docker image sets it to home/jovyan/.kernels–which is fine but annoying since .kernels is hidden and not $HOME.\njupyterhub:\n  hub:\n    config:\n      GitHubOAuthenticator:\n        client_id: <replace with your OAuth id>\n        client_secret: <replace with your OAuth app secret>\n        oauth_callback_url: https://dhub.bluemountain123.live/hub/oauth_callback\n        allowed_organizations:\n          - MyOrg:DaskHub\n        scope:\n          - read:org\n      JupyterHub:\n        authenticator_class: github\n      KubeSpawner:\n        working_dir: /home/jovyan\n  proxy:\n    https:\n      enabled: true\n      hosts:\n        - dhub.bluemountain123.live\n      letsencrypt:\n        contactEmail: your@email.com        \nUpdate the hub\nhelm upgrade --cleanup-on-fail --render-subchart-notes dhub dask/daskhub --namespace dhub --version=2023.1.0 --values dconfig.yaml\nTest\nYou should now see this and can authenticate with GitHub.\n\nSet up the container image\nNow you need to specify the Docker image that will be used. We will use 2 different profiles: Python and R (RStudio).\nEdit the dconfig.yaml file and add the user image info. Note the spacing matters (a lot). I also added some Dask gateway config.\njupyterhub:\n  hub:\n    config:\n      GitHubOAuthenticator:\n        client_id: <replace with your OAuth id>\n        client_secret: <replace with your OAuth app secret>\n        oauth_callback_url: https://dhub.bluemountain123.live/hub/oauth_callback\n        allowed_organizations:\n          - MyOrg:DaskHub\n        scope:\n          - read:org\n      JupyterHub:\n        authenticator_class: github\n  proxy:\n    https:\n      enabled: true\n      hosts:\n        - dhub.bluemountain123.live\n      letsencrypt:\n        contactEmail: your@email.com        \n  singleuser:\n    image:\n      name: openscapes/python\n      tag: f577786\n    cmd: null\n  singleuser:\n    # Defines the default image\n    image:\n      name: openscapes/python\n      tag: f577786\n    profileList:\n      - display_name: \"Python3\"\n        description: \"NASA Openscapes Python image\"\n        default: true\n      - display_name: \"R\"\n        description: \"NASA Openscapes RStudio image\"\n        kubespawner_override:\n          image: openscapes/rocker:a7596b5        \ndask-gateway:\n  gateway:\n    extraConfig:\n      idle: |-\n        # timeout after 30 minutes of inactivity\n        c.KubeClusterConfig.idle_timeout = 1800        \nUpdate the hub\nhelm upgrade --cleanup-on-fail --render-subchart-notes dhub dask/daskhub --namespace dhub --version=2023.1.0 --values dconfig.yaml\nChanging the VM size\nNOT WORKING YET I am stuck on creating the persistent volumes. Needed because you need the user storage somewhere if you have multiple node pools.\n\nkubectl get nodes --show-labels | grep instance-type\nbeta.kubernetes.io/instance-type=Standard_D8s_v3\nCreate a separate disk for user data\nI want the user data to be in a drive different from the VM being spun up for their notebook. Sounds easy here https://z2jh.jupyter.org/en/latest/jupyterhub/customizing/user-storage.html\nbut I cannot string the steps together.\nSteps, I think?\nCreate disk\nSomething like this?\nhttps://bluexp.netapp.com/blog/azure-cvo-blg-azure-kubernetes-service-configuring-persistent-volumes-in-aks\nBut I can’t figure out the steps.\nPVC\nNOT WORKING YET\nIs this pvc.yaml right?\nHow would I point this to the disk that I mount in the step above??\nThis command might have useful info\nKUBE_EDITOR=\"nano\" kubectl edit pvc --namespace=dhub claim-eeholmes\nnana pvc.yaml\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: hub-db-dir\n  labels:\n    component: jupyter\nspec:\n  storageClassName: \"standard\" # name of storage class, it will be default storage class if unspecified.\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: \"40Gi\"\nkubectl create -f pvc.yaml\nTo delete, you need to first edit the pvc yaml file and get rid of pvc protection. It is 2 lines.\nkubectl --namespace=dhub get pvc\nKUBE_EDITOR=\"nano\" kubectl edit pvc --namespace=dhub claim-eeholmes\nThen you can delete\nkubectl --namespace=dhub delete pvc claim-eeholmes\nCheck that it is gone\nkubectl --namespace=dhub get pvc\nif not try\nkubectl --namespace=dhub delete pvc claim-eeholmes --grace-period=0 --force\nPV\nNeed a persistent volume claim too….\nTell the hub about the disk\nhttps://z2jh.jupyter.org/en/latest/jupyterhub/customizing/user-storage.html\nBut see how this is done on the Openscapes 2i2c hub https://github.com/2i2c-org/infrastructure/blob/master/config/clusters/openscapes/common.values.yaml\nI know their set-up is a little different: basehub -> jupyterhub in the helm chart, but I don’t see how the singleuser bit in the yaml file is referencing the nfs in the top of that yaml.\nTroubleshooting\nI cannot clone repos in the JupyterHub. Restart the server. In Jupyter, File > Hub Control Panel > Stop My Server.\nRefs I used\nOverall\nhttps://2i2c.org/service/#getahub\nOpenscapes common.values.yaml https://github.com/2i2c-org/infrastructure/blob/master/config/clusters/openscapes/common.values.yaml\nhttps://artifacthub.io/packages/helm/dask/daskhub\nhttps://github.com/zonca/jupyterhub-deploy-kubernetes-jetstream/blob/master/dask_gateway/dask-hub/config_daskhub.yaml\nhttps://saturncloud.io/blog/how-to-setup-jupyterhub-on-azure/\nhttps://saturncloud.io/blog/jupyterhub-and-azure-ad/\nStorage\nhttps://www.youtube.com/watch?v=Da1qn7-RHvY\nDynamic NFS provisioning 2 https://www.youtube.com/watch?v=DF3v2P8ENEg&t=0s\nDynamic NFS provisioning 1 https://www.youtube.com/watch?v=AavnQzWDTEk&t=0s\nhttps://alan-turing-institute.github.io/hub23-deploy/\nhttps://z2jh.jupyter.org/en/latest/jupyterhub/customizing/user-storage.html\nhttps://learn.microsoft.com/en-us/azure/aks/azure-nfs-volume\nhttps://learn.microsoft.com/en-us/azure/storage/files/storage-files-quick-create-use-linux\nhttps://bluexp.netapp.com/blog/azure-cvo-blg-azure-kubernetes-service-configuring-persistent-volumes-in-aks\nSetting up a shared data disk\nhttps://www.mathworks.com/help/matlab/import_export/work-with-remote-data.html\nhttps://realpython.com/storing-images-in-python/\nS3 access\nhttps://s3fs.readthedocs.io/en/latest/\nhttps://stackoverflow.com/questions/67259323/jupyterhub-access-aws-s3\nhttps://data.lpdaac.earthdatacloud.nasa.gov/s3credentialsREADME\n\n\n\n",
      "last_modified": "2023-06-16T17:40:35-07:00"
    },
    {
      "path": "Setup-Notes.html",
      "author": [],
      "contents": "\n\n\n\n\n\n\n\n\n  \n    \n      \n        \n        \n        \n      \n      \n    \n    \n      \n  User Guide\n\n\n  Hub Set-up\n\n      \n  \n\n\n\n\n\n\n\n\n\n\n\nInstructions for editing config\nLog into https://portal.azure.com/ and once successful, you will\nsee this\n\nClick the JupyterHub icon and you will see this\n\nClick the Connect icon and you will see this. Ignore everything else\nthat you see. I don’t think you need to run the\nkubectl get deployments --all-namespaces=true unless you\nneed to check Kubernetes set up.\n\nType nano config.yaml to get the the JupyterHub config.\nThis is the only file you need to change. cntl-O to write. cntl-X to\nexit.\nAfter you update the config.yaml, you need to tell the\nJupyterHub about the change\nhelm upgrade --cleanup-on-fail jhub jupyterhub/jupyterhub --namespace jhub  --version=2.0.0 --values config.yaml\nIf upgrade was successful, you will see this (plus a bunch of text\nbelow that you can ignore).\n\nWhat a few minutes for your changes to take effect.\n\n\n\n\n\n\n\n",
      "last_modified": "2023-06-16T17:40:35-07:00"
    }
  ],
  "collections": []
}
